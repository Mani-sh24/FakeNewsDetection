{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6Jsp0hFpwNayJjiXOoESB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mani-sh24/FakeNewsDetection/blob/main/fake_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0IWdaXvEPIQ",
        "outputId": "9e3c0c31-ba0b-4d1e-d684-f30ffb494db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/algord/fake-news/versions/1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import kagglehub\n",
        "\n",
        "# Download dataset\n",
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"algord/fake-news\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading and checking missing values freom data\n"
      ],
      "metadata": {
        "id": "uOpEXRVCJCv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_news = pd.read_csv(f\"{path}/FakeNewsNet.csv\")\n",
        "print(f\"\\nDataset loaded: {len(df_news)} rows\")\n",
        "print(f\"Columns: {df_news.columns.tolist()}\")\n",
        "print(f\"\\nMissing values:\\n{df_news.isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cVEYU-TEUkQ",
        "outputId": "66f629a2-7a59-47d7-f26e-c05e3b7c36be"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset loaded: 23196 rows\n",
            "Columns: ['title', 'news_url', 'source_domain', 'tweet_num', 'real']\n",
            "\n",
            "Missing values:\n",
            "title              0\n",
            "news_url         330\n",
            "source_domain    330\n",
            "tweet_num          0\n",
            "real               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['title'] = df_news['title'].fillna(\"\") # filling"
      ],
      "metadata": {
        "id": "ARDONe2lEWwr"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDownloading NLTK resources...\")\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "nltk.download(\"wordnet\", quiet=True)\n",
        "nltk.download(\"omw-1.4\", quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iAc6ZvnEhCM",
        "outputId": "4e0125e7-b869-4c97-e3aa-b8621583a648"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading NLTK resources...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing stop words and cleaning the data and tokenisation\n"
      ],
      "metadata": {
        "id": "QKQe9cHbJNnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and preprocess text\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenization\n",
        "    words = text.split()\n",
        "    # Remove stopwords and lemmatize\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2]\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "Yob4DPyrEk0S"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "removing rows with empty cleaned titles and checkind distribution of dataa"
      ],
      "metadata": {
        "id": "fJ2Fq2gwJVT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCleaning text data...\")\n",
        "df_news[\"cleaned_title\"] = df_news[\"title\"].apply(clean_text)\n",
        "df_news = df_news[df_news[\"cleaned_title\"].str.strip() != \"\"]\n",
        "print(f\"After cleaning: {len(df_news)} rows\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(df_news['real'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnONO02SEp9f",
        "outputId": "993b1bba-27ad-4511-ecf0-3422e53c7b50"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaning text data...\n",
            "After cleaning: 23188 rows\n",
            "\n",
            "Class distribution:\n",
            "real\n",
            "1    17434\n",
            "0     5754\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing data and features"
      ],
      "metadata": {
        "id": "wXCH6358Jd-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nVectorizing text...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    max_df=0.8,           # Ignore terms that appear in >80% of documents\n",
        "    min_df=4,             # Ignore terms that appear in <5 documents\n",
        "    ngram_range=(1, 3),\n",
        "    max_features=10000,\n",
        "    sublinear_tf=True       # Logarithmic scaling\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(df_news[\"cleaned_title\"])\n",
        "y = df_news[\"real\"]\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmTThqQYEyEW",
        "outputId": "457abd39-6601-4af3-932c-20a2a9baccf0"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vectorizing text...\n",
            "Feature matrix shape: (23188, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "# Train model\n",
        "print(\"\\nTraining PassiveAggressiveClassifier...\")\n",
        "model = PassiveAggressiveClassifier(max_iter=1000, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"\\nEvaluating model...\")\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"{'='*50}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw_i5D0vE1zL",
        "outputId": "cf8bb42b-7279-4acc-c4f6-91cb3b31c89a"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set: 18550 samples\n",
            "Test set: 4638 samples\n",
            "\n",
            "Training PassiveAggressiveClassifier...\n",
            "\n",
            "Evaluating model...\n",
            "\n",
            "==================================================\n",
            "Accuracy: 79.99%\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "q0dUKb0XE5Gz"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7h8xn1WE-MZ"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"                Predicted\")\n",
        "print(f\"              Fake    Real\")\n",
        "print(f\"Actual Fake   {cm[0][0]:4d}   {cm[0][1]:4d}\")\n",
        "print(f\"       Real   {cm[1][0]:4d}   {cm[1][1]:4d}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9KDRyvqFA5K",
        "outputId": "007df1d4-cfc1-4ba9-a5d6-ac7c1cffd2a8"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "                Predicted\n",
            "              Fake    Real\n",
            "Actual Fake    710    441\n",
            "       Real    487   3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Fake', 'Real']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxYtmhP_FDq4",
        "outputId": "c050556e-2b1c-4f9b-aca5-8d0ecf4c2507"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.59      0.62      0.60      1151\n",
            "        Real       0.87      0.86      0.87      3487\n",
            "\n",
            "    accuracy                           0.80      4638\n",
            "   macro avg       0.73      0.74      0.74      4638\n",
            "weighted avg       0.80      0.80      0.80      4638\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_news(text):\n",
        "    \"\"\"Predict if news is real or fake\"\"\"\n",
        "    cleaned = clean_text(text)\n",
        "    if not cleaned:\n",
        "        return \"Cannot classify empty text\"\n",
        "\n",
        "    text_tfidf = vectorizer.transform([cleaned])\n",
        "    prediction = model.predict(text_tfidf)[0]\n",
        "    confidence = model.decision_function(text_tfidf)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        return f\"✅ REAL NEWS (confidence: {abs(confidence):.2f})\"\n",
        "    else:\n",
        "        return f\"🚨 FAKE NEWS (confidence: {abs(confidence):.2f})\"\n",
        "\n"
      ],
      "metadata": {
        "id": "CttC8K2wFJQU"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*50}\")\n",
        "print(\"Testing Model:\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "test_examples = [\n",
        "    \"A guy woke up from his grave on his own shocking\",\n",
        "    \"A univerity named 'svvv' in gram baroli bombed 300 dead\",\n",
        "    \"100 dead in a massive explosion left ppl crying in svvv uni\",\n",
        "    \"Scientists develop new vaccine for disease for hiv aids\",\n",
        "    \"Trump just sent a bill to michelle obama that she will never be able to pay in her lifetime\",\n",
        "    \"'End this drama': Rahul Gandhi meets Haryana IPS officer's wife, daughters; 'act against accused officers,' opposition leader tells PM Narendra Modi\"\n",
        "]\n",
        "\n",
        "for example in test_examples:\n",
        "    print(f\"\\nText: '{example}'\")\n",
        "    print(predict_news(example))\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"Model ready for predictions!\")\n",
        "print(f\"{'='*50}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_FPGBDwFQTj",
        "outputId": "80cd4775-d2b1-4d31-969e-dcedb8f72ae3"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Testing Model:\n",
            "==================================================\n",
            "\n",
            "Text: 'A guy woke up from his grave on his own shocking'\n",
            "🚨 FAKE NEWS (confidence: 1.85)\n",
            "\n",
            "Text: 'A univerity named 'svvv' in gram baroli bombed 300 dead'\n",
            "✅ REAL NEWS (confidence: 2.18)\n",
            "\n",
            "Text: '100 dead in a massive explosion left ppl crying in svvv uni'\n",
            "🚨 FAKE NEWS (confidence: 2.32)\n",
            "\n",
            "Text: 'Scientists develop new vaccine for disease for hiv aids'\n",
            "🚨 FAKE NEWS (confidence: 2.27)\n",
            "\n",
            "Text: 'Trump just sent a bill to michelle obama that she will never be able to pay in her lifetime'\n",
            "🚨 FAKE NEWS (confidence: 4.40)\n",
            "\n",
            "Text: ''End this drama': Rahul Gandhi meets Haryana IPS officer's wife, daughters; 'act against accused officers,' opposition leader tells PM Narendra Modi'\n",
            "✅ REAL NEWS (confidence: 5.04)\n",
            "\n",
            "==================================================\n",
            "Model ready for predictions!\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}